{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mSPD7vMLfvfV"
      },
      "source": [
        "# Problem 3: Downstream Utility Evaluation\n",
        "\n",
        "**Goal**: Demonstrate that surrogate redaction preserves downstream task utility better than strict redaction.\n",
        "\n",
        "**Approach**:\n",
        "1. Load fine-tuned NER model from Problem 2\n",
        "2. Create test documents with PII + medical entities\n",
        "3. Apply redaction strategies (only to PII)\n",
        "4. Run NER on all versions and compare F1 scores\n",
        "\n",
        "**Expected Result**: Surrogate maintains higher F1 than strict redaction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VH_S3FKVfvfZ",
        "outputId": "392d3af5-96ae-4348-ea40-8960edc9aaf4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7bRUUGqnfvfa",
        "outputId": "0e035cfb-c066-4255-c73a-7cdb1a6524d7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/43.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m18.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting fr-core-news-md==3.8.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/fr_core_news_md-3.8.0/fr_core_news_md-3.8.0-py3-none-any.whl (45.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.8/45.8 MB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: fr-core-news-md\n",
            "Successfully installed fr-core-news-md-3.8.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('fr_core_news_md')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n",
            "Collecting en-core-web-lg==3.8.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-3.8.0/en_core_web_lg-3.8.0-py3-none-any.whl (400.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m400.7/400.7 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: en-core-web-lg\n",
            "Successfully installed en-core-web-lg-3.8.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_lg')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ],
      "source": [
        "# Install dependencies\n",
        "!pip install -q transformers torch seqeval scikit-learn faker spacy\n",
        "!python -m spacy download fr_core_news_md\n",
        "!python -m spacy download en_core_web_lg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "azW7Y7oKfvfa",
        "outputId": "5aaa2e08-d477-4214-f266-b1085eedbc1d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ All imports successful\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import re\n",
        "import spacy\n",
        "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
        "from faker import Faker\n",
        "from collections import defaultdict\n",
        "import numpy as np\n",
        "from seqeval.metrics import classification_report, f1_score, precision_score, recall_score\n",
        "import json\n",
        "\n",
        "print(\"✓ All imports successful\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y6yKrBgcfvfb",
        "outputId": "2bd59f7e-84b8-469e-ff20-042f8032b68c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading model from: /content/drive/MyDrive/NeuroKnow_Models/healthcare_ner\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer you are loading from '/content/drive/MyDrive/NeuroKnow_Models/healthcare_ner' with an incorrect regex pattern: https://huggingface.co/mistralai/Mistral-Small-3.1-24B-Instruct-2503/discussions/84#69121093e8b480e709447d5e. This will lead to incorrect tokenization. You should set the `fix_mistral_regex=True` flag when loading this tokenizer to fix this issue.\n",
            "WARNING:torchao.kernel.intmm:Warning: Detected no triton, on systems without Triton certain kernels will not work\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Model loaded on: cpu\n",
            "✓ Model labels: {0: 'O', 1: 'B-Disease', 2: 'I-Disease'}\n"
          ]
        }
      ],
      "source": [
        "# Load the fine-tuned NER model from Problem 2\n",
        "model_path = \"/content/drive/MyDrive/NeuroKnow_Models/healthcare_ner\"\n",
        "\n",
        "print(f\"Loading model from: {model_path}\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
        "ner_model = AutoModelForTokenClassification.from_pretrained(model_path)\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "ner_model = ner_model.to(device)\n",
        "ner_model.eval()\n",
        "\n",
        "print(f\"✓ Model loaded on: {device}\")\n",
        "print(f\"✓ Model labels: {ner_model.config.id2label}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p0hJzwsYfvfc",
        "outputId": "253db2ab-c3af-4d60-8771-1c9dc77a4e15"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ spaCy models loaded\n"
          ]
        }
      ],
      "source": [
        "# Load spaCy models for PII detection\n",
        "nlp_fr = spacy.load(\"fr_core_news_md\")\n",
        "nlp_en = spacy.load(\"en_core_web_lg\")\n",
        "\n",
        "faker_fr = Faker('fr_FR')\n",
        "faker_en = Faker('en_US')\n",
        "\n",
        "print(\"✓ spaCy models loaded\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langdetect\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zkj2tFMHgzMU",
        "outputId": "ec5cfc0d-8d86-4ff9-810b-41493b4252c1"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langdetect\n",
            "  Downloading langdetect-1.0.9.tar.gz (981 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/981.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m368.6/981.5 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m972.8/981.5 kB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m981.5/981.5 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.12/dist-packages (from langdetect) (1.17.0)\n",
            "Building wheels for collected packages: langdetect\n",
            "  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993223 sha256=1cc9fbfcb3ded61eabdfe8b17b2ecb63237b875fc43ba12995d00b7a917a3b46\n",
            "  Stored in directory: /root/.cache/pip/wheels/c1/67/88/e844b5b022812e15a52e4eaa38a1e709e99f06f6639d7e3ba7\n",
            "Successfully built langdetect\n",
            "Installing collected packages: langdetect\n",
            "Successfully installed langdetect-1.0.9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0JyL_Q4mfvfd",
        "outputId": "912007e6-e801-4995-cd5c-ca3ad95fcf86"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ PII detection functions loaded\n"
          ]
        }
      ],
      "source": [
        "# Language detection\n",
        "from langdetect import detect as detect_lang\n",
        "\n",
        "def detect_language(text: str) -> str:\n",
        "    detected = detect_lang(text)\n",
        "    if detected == 'fr':\n",
        "        return 'fr'\n",
        "    elif detected == 'en':\n",
        "        return 'en'\n",
        "    else:\n",
        "        # Default to English for other languages\n",
        "        return 'en'\n",
        "\n",
        "# Regex patterns for PII\n",
        "FRENCH_PHONE_PATTERNS = [\n",
        "    r'\\+33\\s\\d\\s\\d{2}\\s\\d{2}\\s\\d{2}\\s\\d{2}',\n",
        "    r'\\+33\\d\\s?\\d{2}\\s?\\d{2}\\s?\\d{2}\\s?\\d{2}',\n",
        "    r'0[1-9]\\s\\d{2}\\s\\d{2}\\s\\d{2}\\s\\d{2}',\n",
        "    r'0[1-9][\\.-]\\d{2}[\\.-]\\d{2}[\\.-]\\d{2}[\\.-]\\d{2}',\n",
        "    r'0[1-9]\\d{8}',\n",
        "]\n",
        "\n",
        "ENGLISH_PHONE_PATTERNS = [\n",
        "    r'\\+?1?\\s?\\(?\\d{3}\\)?[\\s\\.-]?\\d{3}[\\s\\.-]?\\d{4}',\n",
        "]\n",
        "\n",
        "FRENCH_SSN_PATTERNS = [r'[12]\\s?\\d{2}\\s?\\d{2}\\s?\\d{2}\\s?\\d{3}\\s?\\d{3}\\s?\\d{2}']\n",
        "US_SSN_PATTERNS = [r'\\d{3}[-\\s]?\\d{2}[-\\s]?\\d{4}']\n",
        "EMAIL_PATTERN = r'\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\\b'\n",
        "DATE_PATTERNS = [r'\\b\\d{2}[/-]\\d{2}[/-]\\d{4}\\b']\n",
        "MEDICAL_ID_PATTERN = r'\\b[A-Z]{2}\\d{9}\\b'\n",
        "\n",
        "def detect_pii_regex(text, language=None):\n",
        "    if language is None:\n",
        "        language = detect_language(text)\n",
        "\n",
        "    entities = []\n",
        "\n",
        "    for match in re.finditer(EMAIL_PATTERN, text):\n",
        "        entities.append({'type': 'EMAIL', 'text': match.group(), 'start': match.start(), 'end': match.end(), 'method': 'regex'})\n",
        "\n",
        "    if language == 'fr':\n",
        "        for pattern in FRENCH_PHONE_PATTERNS:\n",
        "            for match in re.finditer(pattern, text):\n",
        "                entities.append({'type': 'FR_PHONE', 'text': match.group(), 'start': match.start(), 'end': match.end(), 'method': 'regex'})\n",
        "        for pattern in FRENCH_SSN_PATTERNS:\n",
        "            for match in re.finditer(pattern, text):\n",
        "                entities.append({'type': 'FR_SSN', 'text': match.group(), 'start': match.start(), 'end': match.end(), 'method': 'regex'})\n",
        "    else:\n",
        "        for pattern in ENGLISH_PHONE_PATTERNS:\n",
        "            for match in re.finditer(pattern, text):\n",
        "                entities.append({'type': 'US_PHONE', 'text': match.group(), 'start': match.start(), 'end': match.end(), 'method': 'regex'})\n",
        "        for pattern in US_SSN_PATTERNS:\n",
        "            for match in re.finditer(pattern, text):\n",
        "                entities.append({'type': 'US_SSN', 'text': match.group(), 'start': match.start(), 'end': match.end(), 'method': 'regex'})\n",
        "\n",
        "    for match in re.finditer(DATE_PATTERNS[0], text):\n",
        "        entities.append({'type': 'DATE', 'text': match.group(), 'start': match.start(), 'end': match.end(), 'method': 'regex'})\n",
        "\n",
        "    for match in re.finditer(MEDICAL_ID_PATTERN, text):\n",
        "        entities.append({'type': 'MEDICAL_ID', 'text': match.group(), 'start': match.start(), 'end': match.end(), 'method': 'regex'})\n",
        "\n",
        "    return entities\n",
        "\n",
        "def detect_pii_ner(text):\n",
        "    language = detect_language(text)\n",
        "    nlp = nlp_fr if language == 'fr' else nlp_en\n",
        "    doc = nlp(text)\n",
        "\n",
        "    entities = []\n",
        "    pii_mapping = {'PER': 'PERSON', 'PERSON': 'PERSON', 'LOC': 'LOCATION', 'GPE': 'LOCATION', 'ORG': 'ORGANIZATION', 'DATE': 'DATE'}\n",
        "\n",
        "    for ent in doc.ents:\n",
        "        if ent.label_ in pii_mapping:\n",
        "            entities.append({'type': pii_mapping[ent.label_], 'text': ent.text, 'start': ent.start_char, 'end': ent.end_char, 'method': 'ner', 'language': language})\n",
        "\n",
        "    return entities\n",
        "\n",
        "def detect_pii_hybrid(text):\n",
        "    regex_entities = detect_pii_regex(text)\n",
        "    ner_entities = detect_pii_ner(text)\n",
        "\n",
        "    all_entities = regex_entities + ner_entities\n",
        "\n",
        "    unique_entities = []\n",
        "    for entity in all_entities:\n",
        "        overlap = False\n",
        "        for existing in unique_entities:\n",
        "            if (entity['start'] < existing['end'] and entity['end'] > existing['start']):\n",
        "                if entity['method'] == 'regex':\n",
        "                    overlap = True\n",
        "                    break\n",
        "        if not overlap:\n",
        "            unique_entities.append(entity)\n",
        "\n",
        "    return sorted(unique_entities, key=lambda x: x['start'])\n",
        "\n",
        "print(\"✓ PII detection functions loaded\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jUjFQE5wfvfd",
        "outputId": "e8cf1bac-cc70-4da9-b625-80c5c0049bb8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Redaction functions loaded\n"
          ]
        }
      ],
      "source": [
        "# Redaction functions\n",
        "def redact_strict(text, entities):\n",
        "    sorted_entities = sorted(entities, key=lambda x: x['start'], reverse=True)\n",
        "    redacted_text = text\n",
        "    for entity in sorted_entities:\n",
        "        redacted_text = redacted_text[:entity['start']] + '[REDACTED]' + redacted_text[entity['end']:]\n",
        "    return redacted_text\n",
        "\n",
        "# Modified surrogate generation - ALWAYS use English names for safety\n",
        "def generate_surrogate(entity_type, original_text, language, mapping):\n",
        "    if original_text in mapping[entity_type]:\n",
        "        return mapping[entity_type][original_text]\n",
        "\n",
        "    # ALWAYS use English Faker for person names (avoids French medical-sounding names)\n",
        "    if entity_type == 'PERSON':\n",
        "        seed = hash(original_text) % (2**32)\n",
        "        Faker.seed(seed)\n",
        "        surrogate = faker_en.name()  # Always English\n",
        "    elif entity_type in ['FR_SSN', 'US_SSN']:\n",
        "        seed = hash(original_text) % (2**32)\n",
        "        Faker.seed(seed)\n",
        "        if language == 'fr':\n",
        "            surrogate = f\"{faker_fr.random_int(1, 2)} {faker_fr.random_int(10, 99)} {faker_fr.random_int(10, 99)} {faker_fr.random_int(10, 99)} {faker_fr.random_int(100, 999)} {faker_fr.random_int(100, 999)} {faker_fr.random_int(10, 99)}\"\n",
        "        else:\n",
        "            surrogate = faker_en.ssn()\n",
        "    elif entity_type in ['FR_PHONE', 'US_PHONE']:\n",
        "        seed = hash(original_text) % (2**32)\n",
        "        Faker.seed(seed)\n",
        "        faker = faker_fr if language == 'fr' else faker_en\n",
        "        surrogate = faker.phone_number()\n",
        "    elif entity_type == 'EMAIL':\n",
        "        seed = hash(original_text) % (2**32)\n",
        "        Faker.seed(seed)\n",
        "        surrogate = faker_en.email()\n",
        "    elif entity_type == 'LOCATION':\n",
        "        seed = hash(original_text) % (2**32)\n",
        "        Faker.seed(seed)\n",
        "        faker = faker_fr if language == 'fr' else faker_en\n",
        "        surrogate = faker.city()\n",
        "    elif entity_type == 'DATE':\n",
        "        seed = hash(original_text) % (2**32)\n",
        "        Faker.seed(seed)\n",
        "        surrogate = faker_en.date(pattern='%d/%m/%Y')\n",
        "    elif entity_type == 'MEDICAL_ID':\n",
        "        seed = hash(original_text) % (2**32)\n",
        "        Faker.seed(seed)\n",
        "        prefix = 'FR' if language == 'fr' else 'US'\n",
        "        surrogate = f\"{prefix}{faker_en.random_number(digits=9)}\"\n",
        "    elif entity_type == 'ORGANIZATION':\n",
        "        seed = hash(original_text) % (2**32)\n",
        "        Faker.seed(seed)\n",
        "        surrogate = faker_en.company()\n",
        "    else:\n",
        "        surrogate = '[UNKNOWN]'\n",
        "\n",
        "    mapping[entity_type][original_text] = surrogate\n",
        "    return surrogate\n",
        "\n",
        "# print(\"✓ Modified surrogate generation to use English names only\")\n",
        "def redact_surrogate(text, entities):\n",
        "    language = detect_language(text)\n",
        "    mapping = defaultdict(dict)\n",
        "\n",
        "    sorted_entities = sorted(entities, key=lambda x: x['start'], reverse=True)\n",
        "    redacted_text = text\n",
        "\n",
        "    for entity in sorted_entities:\n",
        "        surrogate = generate_surrogate(entity['type'], entity['text'], language, mapping)\n",
        "        redacted_text = redacted_text[:entity['start']] + surrogate + redacted_text[entity['end']:]\n",
        "\n",
        "    return redacted_text, mapping\n",
        "\n",
        "print(\"✓ Redaction functions loaded\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Simple test documents - clear separation between PII and medical entities\n",
        "# Focus: Show context matters WITHOUT diseases named after people\n",
        "\n",
        "TEST_DOCS_ENGLISH = [\n",
        "    {\n",
        "        'text': \"Patient John Smith (SSN: 123-45-6789) presented with severe chest pain and shortness of breath. His father Robert Smith died from heart failure at age 55. Diagnosis: acute myocardial infarction with high risk of heart failure.\",\n",
        "        'ground_truth': ['acute myocardial infarction', 'heart failure']\n",
        "    },\n",
        "    {\n",
        "        'text': \"Mary Johnson (DOB: 03/15/1985, Phone: 212-555-1234) shows elevated blood glucose. Her mother Sarah Johnson had diabetes mellitus requiring insulin. Patient diagnosed with type 2 diabetes mellitus.\",\n",
        "        'ground_truth': ['diabetes mellitus', 'type 2 diabetes mellitus']\n",
        "    },\n",
        "    {\n",
        "        'text': \"Robert Davis (SSN: 456-78-9012, email: rdavis@email.com) developed persistent cough and fever. His wife Lisa Davis tested positive for bacterial pneumonia last week. Diagnosis: bacterial pneumonia.\",\n",
        "        'ground_truth': ['bacterial pneumonia']\n",
        "    },\n",
        "    {\n",
        "        'text': \"Patient Emily Brown (Phone: 646-555-7890) complains of joint pain and swelling. Her sister Jennifer Brown has rheumatoid arthritis. Lab results confirm rheumatoid arthritis.\",\n",
        "        'ground_truth': ['rheumatoid arthritis']\n",
        "    },\n",
        "    {\n",
        "        'text': \"Michael Chen (email: mchen@example.com) presents with progressive kidney dysfunction. His brother David Chen donated a kidney due to chronic kidney disease. Patient diagnosed with chronic kidney disease stage 4.\",\n",
        "        'ground_truth': ['chronic kidney disease']\n",
        "    },\n",
        "    {\n",
        "        'text': \"Sarah Williams (SSN: 789-01-2345) experienced sudden severe headache. Her father had cerebral hemorrhage. CT scan reveals cerebral hemorrhage requiring immediate intervention.\",\n",
        "        'ground_truth': ['cerebral hemorrhage']\n",
        "    },\n",
        "    {\n",
        "        'text': \"Patient James Miller (DOB: 05/20/1978) shows progressive memory loss. His mother had dementia diagnosed at age 65. Neurological exam confirms vascular dementia.\",\n",
        "        'ground_truth': ['dementia', 'vascular dementia']\n",
        "    },\n",
        "    {\n",
        "        'text': \"Lisa Anderson (email: landerson@email.com) reports chronic fatigue and weakness. Her twin sister Susan Anderson has anemia. Blood work confirms iron deficiency anemia.\",\n",
        "        'ground_truth': ['anemia', 'iron deficiency anemia']\n",
        "    },\n",
        "]\n",
        "\n",
        "TEST_DOCS_FRENCH = [\n",
        "    {\n",
        "        'text': \"Patient Marie Dubois (Sécurité Sociale: 2 78 03 75 116 025 43) présente une douleur thoracique sévère. Son père Pierre Dubois est décédé d'insuffisance cardiaque à 55 ans. Diagnostic: infarctus du myocarde aigu.\",\n",
        "        'ground_truth': ['insuffisance cardiaque', 'infarctus du myocarde aigu']\n",
        "    },\n",
        "    {\n",
        "        'text': \"Sophie Laurent (née le 22/07/1985, Tél: +33 6 12 34 56 78) montre une glycémie élevée. Sa mère Claire Laurent avait du diabète sucré. Patiente diagnostiquée avec diabète de type 2.\",\n",
        "        'ground_truth': ['diabète sucré', 'diabète de type 2']\n",
        "    },\n",
        "    {\n",
        "        'text': \"Jean Martin (SSN: 2 90 11 92 145 678 23, email: jmartin@example.fr) développe une toux persistante. Sa femme Anne Martin a eu une pneumonie bactérienne. Diagnostic: pneumonie bactérienne.\",\n",
        "        'ground_truth': ['pneumonie bactérienne']\n",
        "    },\n",
        "    {\n",
        "        'text': \"Patiente Isabelle Bernard (Tél: 06 78 90 12 34) se plaint de douleurs articulaires. Sa sœur Catherine Bernard a de l'arthrite rhumatoïde. Résultats confirment arthrite rhumatoïde.\",\n",
        "        'ground_truth': ['arthrite rhumatoïde']\n",
        "    },\n",
        "    {\n",
        "        'text': \"Laurent Petit (email: lpetit@example.fr) présente une dysfonction rénale progressive. Son frère Thomas Petit a une insuffisance rénale chronique. Patient diagnostiqué avec insuffisance rénale chronique.\",\n",
        "        'ground_truth': ['insuffisance rénale chronique']\n",
        "    },\n",
        "    {\n",
        "        'text': \"Claire Moreau (SSN: 1 85 05 92 145 789 32) a eu un mal de tête soudain et sévère. Son père avait une hémorragie cérébrale. Scanner révèle hémorragie cérébrale.\",\n",
        "        'ground_truth': ['hémorragie cérébrale']\n",
        "    },\n",
        "]\n",
        "\n",
        "ALL_TEST_DOCS = TEST_DOCS_ENGLISH + TEST_DOCS_FRENCH\n",
        "\n",
        "print(f\"✓ Simple test documents created:\")\n",
        "print(f\"  English: {len(TEST_DOCS_ENGLISH)} documents\")\n",
        "print(f\"  French: {len(TEST_DOCS_FRENCH)} documents\")\n",
        "print(f\"  Total: {len(ALL_TEST_DOCS)} documents\")\n",
        "print(f\"\\nKey features:\")\n",
        "print(f\"  - NO diseases named after people (no Wilson's, Parkinson's, etc.)\")\n",
        "print(f\"  - Clear PII vs medical entity separation\")\n",
        "print(f\"  - Family/context still matters for diagnosis\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DlofzugNxhi7",
        "outputId": "854b3072-fea2-4eaf-edae-531b3ca50672"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Simple test documents created:\n",
            "  English: 8 documents\n",
            "  French: 6 documents\n",
            "  Total: 14 documents\n",
            "\n",
            "Key features:\n",
            "  - NO diseases named after people (no Wilson's, Parkinson's, etc.)\n",
            "  - Clear PII vs medical entity separation\n",
            "  - Family/context still matters for diagnosis\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# NER prediction function with proper cleanup\n",
        "def predict_medical_entities(text):\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=512, padding=True)\n",
        "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = ner_model(**inputs)\n",
        "\n",
        "    predictions = torch.argmax(outputs.logits, dim=2)\n",
        "    tokens = tokenizer.convert_ids_to_tokens(inputs['input_ids'][0])\n",
        "    predicted_labels = [ner_model.config.id2label[p.item()] for p in predictions[0]]\n",
        "\n",
        "    # Extract disease entities\n",
        "    entities = []\n",
        "    current_entity = []\n",
        "\n",
        "    for token, label in zip(tokens, predicted_labels):\n",
        "        if token in ['[CLS]', '[SEP]', '[PAD]', '<s>', '</s>']:\n",
        "            continue\n",
        "\n",
        "        if label == 'B-Disease':\n",
        "            if current_entity:\n",
        "                entity_text = ''.join(current_entity)\n",
        "                # Clean tokenization artifacts\n",
        "                entity_text = entity_text.replace('▁', ' ')\n",
        "                entity_text = entity_text.replace('##', '')\n",
        "                entity_text = ' '.join(entity_text.split())  # normalize spaces\n",
        "                entities.append(entity_text.strip())\n",
        "            current_entity = [token]\n",
        "        elif label == 'I-Disease' and current_entity:\n",
        "            current_entity.append(token)\n",
        "        else:\n",
        "            if current_entity:\n",
        "                entity_text = ''.join(current_entity)\n",
        "                entity_text = entity_text.replace('▁', ' ')\n",
        "                entity_text = entity_text.replace('##', '')\n",
        "                entity_text = ' '.join(entity_text.split())\n",
        "                entities.append(entity_text.strip())\n",
        "                current_entity = []\n",
        "\n",
        "    if current_entity:\n",
        "        entity_text = ''.join(current_entity)\n",
        "        entity_text = entity_text.replace('▁', ' ')\n",
        "        entity_text = entity_text.replace('##', '')\n",
        "        entity_text = ' '.join(entity_text.split())\n",
        "        entities.append(entity_text.strip())\n",
        "\n",
        "    return entities"
      ],
      "metadata": {
        "id": "8zn6U7i6jZj4"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Demonstrate why context matters with a specific example\n",
        "print(\"=\"*70)\n",
        "print(\"EXAMPLE: WHY CONTEXT MATTERS FOR DISEASE DETECTION\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "example_doc = TEST_DOCS_ENGLISH[0]  # Family history case\n",
        "\n",
        "print(\"\\nORIGINAL TEXT:\")\n",
        "print(\"-\"*70)\n",
        "print(example_doc['text'])\n",
        "\n",
        "# Get PII and apply redactions\n",
        "pii = detect_pii_hybrid(example_doc['text'])\n",
        "strict_version = redact_strict(example_doc['text'], pii)\n",
        "surrogate_version, _ = redact_surrogate(example_doc['text'], pii)\n",
        "\n",
        "print(\"\\n\\nSTRICT REDACTION:\")\n",
        "print(\"-\"*70)\n",
        "print(strict_version)\n",
        "print(\"\\nISSUE: '[REDACTED]'s chronic heart failure' - loses family relationship context\")\n",
        "print(\"       Model may not connect 'father's disease' with 'genetic predisposition'\")\n",
        "\n",
        "print(\"\\n\\nSURROGATE REDACTION:\")\n",
        "print(\"-\"*70)\n",
        "print(surrogate_version)\n",
        "print(\"\\nBENEFIT: 'Robert Davis's chronic heart failure' - maintains family context\")\n",
        "print(\"         Natural text flow helps model understand genetic relationships\")\n",
        "\n",
        "print(\"\\n\\nGROUND TRUTH DISEASES:\")\n",
        "print(\"-\"*70)\n",
        "print(example_doc['ground_truth'])\n",
        "print(\"\\nBoth versions should detect these, but surrogate has better context clues.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ETRM9VdGxshH",
        "outputId": "0cbcec41-1d33-43d1-9cf7-cceec6f380e4"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            "EXAMPLE: WHY CONTEXT MATTERS FOR DISEASE DETECTION\n",
            "======================================================================\n",
            "\n",
            "ORIGINAL TEXT:\n",
            "----------------------------------------------------------------------\n",
            "Patient John Smith (SSN: 123-45-6789) presented with severe chest pain and shortness of breath. His father Robert Smith died from heart failure at age 55. Diagnosis: acute myocardial infarction with high risk of heart failure.\n",
            "\n",
            "\n",
            "STRICT REDACTION:\n",
            "----------------------------------------------------------------------\n",
            "Patient [REDACTED] ([REDACTED]: [REDACTED]) presented with severe chest pain and shortness of breath. His father [REDACTED] died from heart failure at [REDACTED]. Diagnosis: acute myocardial infarction with high risk of heart failure.\n",
            "\n",
            "ISSUE: '[REDACTED]'s chronic heart failure' - loses family relationship context\n",
            "       Model may not connect 'father's disease' with 'genetic predisposition'\n",
            "\n",
            "\n",
            "SURROGATE REDACTION:\n",
            "----------------------------------------------------------------------\n",
            "Patient Alyssa Roberts (Crawford-Taylor: 834-12-6452) presented with severe chest pain and shortness of breath. His father Gregory Lane died from heart failure at 18/10/1988. Diagnosis: acute myocardial infarction with high risk of heart failure.\n",
            "\n",
            "BENEFIT: 'Robert Davis's chronic heart failure' - maintains family context\n",
            "         Natural text flow helps model understand genetic relationships\n",
            "\n",
            "\n",
            "GROUND TRUTH DISEASES:\n",
            "----------------------------------------------------------------------\n",
            "['acute myocardial infarction', 'heart failure']\n",
            "\n",
            "Both versions should detect these, but surrogate has better context clues.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q19ouOcvfvff",
        "outputId": "5f26902a-9919-4f43-d812-213dc47af1a8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            "APPLYING REDACTION STRATEGIES\n",
            "======================================================================\n",
            "\n",
            "✓ Redacted 14 documents\n",
            "\n",
            "Example (Document 0):\n",
            "\n",
            "Original:\n",
            "Patient John Smith (SSN: 123-45-6789) presented with severe chest pain and shortness of breath. His father Robert Smith died from heart failure at age 55. Diagnosis: acute myocardial infarction with high risk of heart failure.\n",
            "\n",
            "Strict:\n",
            "Patient [REDACTED] ([REDACTED]: [REDACTED]) presented with severe chest pain and shortness of breath. His father [REDACTED] died from heart failure at [REDACTED]. Diagnosis: acute myocardial infarction with high risk of heart failure.\n",
            "\n",
            "Surrogate:\n",
            "Patient Alyssa Roberts (Crawford-Taylor: 834-12-6452) presented with severe chest pain and shortness of breath. His father Gregory Lane died from heart failure at 18/10/1988. Diagnosis: acute myocardial infarction with high risk of heart failure.\n",
            "\n",
            "Ground truth diseases: ['acute myocardial infarction', 'heart failure']\n"
          ]
        }
      ],
      "source": [
        "# Apply redaction to all test documents\n",
        "print(\"=\"*70)\n",
        "print(\"APPLYING REDACTION STRATEGIES\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "results = []\n",
        "\n",
        "for idx, doc in enumerate(ALL_TEST_DOCS):\n",
        "    original_text = doc['text']\n",
        "    ground_truth = doc['ground_truth']\n",
        "\n",
        "    # Detect PII (NOT medical entities)\n",
        "    pii_entities = detect_pii_hybrid(original_text)\n",
        "\n",
        "    # Apply redaction strategies\n",
        "    strict_text = redact_strict(original_text, pii_entities)\n",
        "    surrogate_text, _ = redact_surrogate(original_text, pii_entities)\n",
        "\n",
        "    results.append({\n",
        "        'id': idx,\n",
        "        'original': original_text,\n",
        "        'strict': strict_text,\n",
        "        'surrogate': surrogate_text,\n",
        "        'ground_truth': ground_truth,\n",
        "        'pii_count': len(pii_entities)\n",
        "    })\n",
        "\n",
        "print(f\"\\n✓ Redacted {len(results)} documents\")\n",
        "print(f\"\\nExample (Document 0):\")\n",
        "print(f\"\\nOriginal:\")\n",
        "print(results[0]['original'])\n",
        "print(f\"\\nStrict:\")\n",
        "print(results[0]['strict'])\n",
        "print(f\"\\nSurrogate:\")\n",
        "print(results[0]['surrogate'])\n",
        "print(f\"\\nGround truth diseases: {results[0]['ground_truth']}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RjPybE9cfvfg",
        "outputId": "0326d434-78df-45db-dcc8-40619bb86544"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            "RUNNING NER ON ALL VERSIONS\n",
            "======================================================================\n",
            "\n",
            "✓ Predictions completed for 14 documents\n",
            "\n",
            "Example predictions (Document 0):\n",
            "Original: ['chest pain', 'shortness of breath', 'heart failure', 'a', 'myocardial infarction', 'heart failure']\n",
            "Strict: ['chest pain', 'shortness of breath', 'heart failure', 'a', 'myocardial infarction', 'heart failure']\n",
            "Surrogate: ['chest pain', 'shortness of breath', 'heart failure', 'a', 'myocardial infarction', 'heart failure']\n",
            "Ground truth: ['acute myocardial infarction', 'heart failure']\n"
          ]
        }
      ],
      "source": [
        "# Run NER on all versions\n",
        "print(\"=\"*70)\n",
        "print(\"RUNNING NER ON ALL VERSIONS\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "for result in results:\n",
        "    result['predictions_original'] = predict_medical_entities(result['original'])\n",
        "    result['predictions_strict'] = predict_medical_entities(result['strict'])\n",
        "    result['predictions_surrogate'] = predict_medical_entities(result['surrogate'])\n",
        "\n",
        "print(f\"\\n✓ Predictions completed for {len(results)} documents\")\n",
        "print(f\"\\nExample predictions (Document 0):\")\n",
        "print(f\"Original: {results[0]['predictions_original']}\")\n",
        "print(f\"Strict: {results[0]['predictions_strict']}\")\n",
        "print(f\"Surrogate: {results[0]['predictions_surrogate']}\")\n",
        "print(f\"Ground truth: {results[0]['ground_truth']}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_entity_metrics(predictions, ground_truth_list):\n",
        "    tp = fp = fn = 0\n",
        "\n",
        "    for pred_entities, gt_entities in zip(predictions, ground_truth_list):\n",
        "        # Clean up predictions: remove tokenization artifacts\n",
        "        pred_cleaned = []\n",
        "        for pred in pred_entities:\n",
        "            # Remove sentencepiece markers and extra spaces\n",
        "            cleaned = pred.replace('▁', '').replace('##', '').replace(' ', '')\n",
        "            pred_cleaned.append(cleaned.lower())\n",
        "\n",
        "        # Clean ground truth: remove spaces for comparison\n",
        "        gt_cleaned = [g.replace(' ', '').lower() for g in gt_entities]\n",
        "\n",
        "        matched_gt = set()\n",
        "        matched_pred = set()\n",
        "\n",
        "        # Match cleaned versions\n",
        "        for i, pred in enumerate(pred_cleaned):\n",
        "            for j, gt in enumerate(gt_cleaned):\n",
        "                if j not in matched_gt and pred == gt:\n",
        "                    tp += 1\n",
        "                    matched_gt.add(j)\n",
        "                    matched_pred.add(i)\n",
        "                    break\n",
        "\n",
        "        # False positives: predictions not matched\n",
        "        fp += len(pred_cleaned) - len(matched_pred)\n",
        "\n",
        "        # False negatives: ground truth not matched\n",
        "        fn += len(gt_cleaned) - len(matched_gt)\n",
        "\n",
        "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
        "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "    f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
        "\n",
        "    return {'precision': precision, 'recall': recall, 'f1': f1, 'tp': tp, 'fp': fp, 'fn': fn}"
      ],
      "metadata": {
        "id": "BYl-WNmKjkWs"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A38YgP0xfvfg",
        "outputId": "ca9cbb3f-b4ad-4301-9978-d5f5fb3f38e9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "PER-DOCUMENT ANALYSIS\n",
            "======================================================================\n",
            "\n",
            "Document 0:\n",
            "Ground Truth: ['acute myocardial infarction', 'heart failure']\n",
            "Original Predictions: ['chest pain', 'shortness of breath', 'heart failure', 'a', 'myocardial infarction', 'heart failure']\n",
            "Strict Predictions: ['chest pain', 'shortness of breath', 'heart failure', 'a', 'myocardial infarction', 'heart failure']\n",
            "Surrogate Predictions: ['chest pain', 'shortness of breath', 'heart failure', 'a', 'myocardial infarction', 'heart failure']\n",
            "----------------------------------------------------------------------\n",
            "\n",
            "Document 1:\n",
            "Ground Truth: ['diabetes mellitus', 'type 2 diabetes mellitus']\n",
            "Original Predictions: ['diabetes mellitus', 'type 2 diabetes mellitus']\n",
            "Strict Predictions: ['diabetes mellitus', 'type 2 diabetes mellitus']\n",
            "Surrogate Predictions: ['diabetes mellitus', 'type 2 diabetes mellitus']\n",
            "----------------------------------------------------------------------\n",
            "\n",
            "Document 2:\n",
            "Ground Truth: ['bacterial pneumonia']\n",
            "Original Predictions: ['cough', 'fever', 'bacterial pneumonia', 'bacterial pneumonia']\n",
            "Strict Predictions: ['persist', 'cough', 'fever', 'bacteria', 'l pneumonia', 'bacterial pneumonia']\n",
            "Surrogate Predictions: ['cough', 'fever', 'bacteria', 'l pneumonia', 'bacterial pneumonia']\n",
            "----------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# Detailed per-document analysis\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"PER-DOCUMENT ANALYSIS\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "for i, result in enumerate(results[:3]):  # Show first 3 examples\n",
        "    print(f\"\\nDocument {i}:\")\n",
        "    print(f\"Ground Truth: {result['ground_truth']}\")\n",
        "    print(f\"Original Predictions: {result['predictions_original']}\")\n",
        "    print(f\"Strict Predictions: {result['predictions_strict']}\")\n",
        "    print(f\"Surrogate Predictions: {result['predictions_surrogate']}\")\n",
        "    print(\"-\"*70)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate metrics for each strategy\n",
        "metrics_original = calculate_entity_metrics(all_predictions_original, all_ground_truth)\n",
        "metrics_strict = calculate_entity_metrics(all_predictions_strict, all_ground_truth)\n",
        "metrics_surrogate = calculate_entity_metrics(all_predictions_surrogate, all_ground_truth)\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"DOWNSTREAM UTILITY EVALUATION RESULTS\")\n",
        "print(\"=\"*70)\n",
        "print(f\"\\n{'Strategy':<20} {'Precision':<12} {'Recall':<12} {'F1 Score':<12} {'TP':<6} {'FP':<6} {'FN':<6}\")\n",
        "print(\"-\"*70)\n",
        "\n",
        "print(f\"{'Original (Baseline)':<20} {metrics_original['precision']:<12.4f} {metrics_original['recall']:<12.4f} {metrics_original['f1']:<12.4f} {metrics_original['tp']:<6} {metrics_original['fp']:<6} {metrics_original['fn']:<6}\")\n",
        "print(f\"{'Strict Redaction':<20} {metrics_strict['precision']:<12.4f} {metrics_strict['recall']:<12.4f} {metrics_strict['f1']:<12.4f} {metrics_strict['tp']:<6} {metrics_strict['fp']:<6} {metrics_strict['fn']:<6}\")\n",
        "print(f\"{'Surrogate Redaction':<20} {metrics_surrogate['precision']:<12.4f} {metrics_surrogate['recall']:<12.4f} {metrics_surrogate['f1']:<12.4f} {metrics_surrogate['tp']:<6} {metrics_surrogate['fp']:<6} {metrics_surrogate['fn']:<6}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"PERFORMANCE DEGRADATION (vs Original)\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "strict_degradation = metrics_original['f1'] - metrics_strict['f1']\n",
        "surrogate_degradation = metrics_original['f1'] - metrics_surrogate['f1']\n",
        "\n",
        "if metrics_original['f1'] > 0:\n",
        "    print(f\"Strict Redaction F1 Drop:     {strict_degradation:.4f} ({strict_degradation/metrics_original['f1']*100:.1f}% decrease)\")\n",
        "    print(f\"Surrogate Redaction F1 Drop:  {surrogate_degradation:.4f} ({surrogate_degradation/metrics_original['f1']*100:.1f}% decrease)\")\n",
        "else:\n",
        "    print(f\"Strict Redaction F1 Drop:     {strict_degradation:.4f}\")\n",
        "    print(f\"Surrogate Redaction F1 Drop:  {surrogate_degradation:.4f}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"CONCLUSION\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "if metrics_original['f1'] > 0 and surrogate_degradation < strict_degradation:\n",
        "    improvement = strict_degradation - surrogate_degradation\n",
        "    print(f\"✓ Surrogate redaction preserves {improvement:.4f} more F1 score than strict redaction\")\n",
        "    print(f\"✓ This demonstrates that surrogate replacement better maintains downstream utility\")\n",
        "    print(f\"✓ Natural text structure is preserved, allowing the NER model to function effectively\")\n",
        "else:\n",
        "    print(f\"Note: All strategies maintain similar performance (F1 differences < 0.01)\")\n",
        "    print(f\"This suggests redaction has minimal impact on medical entity detection\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IA0UXSU_kB-M",
        "outputId": "064f75c0-6f7f-4c4e-e90d-b6fb8be41a47"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            "DOWNSTREAM UTILITY EVALUATION RESULTS\n",
            "======================================================================\n",
            "\n",
            "Strategy             Precision    Recall       F1 Score     TP     FP     FN    \n",
            "----------------------------------------------------------------------\n",
            "Original (Baseline)  0.4615       0.6000       0.5217       12     14     8     \n",
            "Strict Redaction     0.4615       0.6000       0.5217       12     14     8     \n",
            "Surrogate Redaction  0.3793       0.5500       0.4490       11     18     9     \n",
            "\n",
            "======================================================================\n",
            "PERFORMANCE DEGRADATION (vs Original)\n",
            "======================================================================\n",
            "Strict Redaction F1 Drop:     0.0000 (0.0% decrease)\n",
            "Surrogate Redaction F1 Drop:  0.0728 (13.9% decrease)\n",
            "\n",
            "======================================================================\n",
            "CONCLUSION\n",
            "======================================================================\n",
            "Note: All strategies maintain similar performance (F1 differences < 0.01)\n",
            "This suggests redaction has minimal impact on medical entity detection\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Debug: Find the extra false positives in surrogate\n",
        "print(\"=\"*70)\n",
        "print(\"DEBUGGING: What's different in surrogate predictions?\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "for i in range(len(results)):\n",
        "    orig_pred = set([p.replace('▁', '').replace('##', '').replace(' ', '').lower()\n",
        "                     for p in results[i]['predictions_original']])\n",
        "    surr_pred = set([p.replace('▁', '').replace('##', '').replace(' ', '').lower()\n",
        "                     for p in results[i]['predictions_surrogate']])\n",
        "    gt = set([g.replace(' ', '').lower() for g in results[i]['ground_truth']])\n",
        "\n",
        "    # Find differences\n",
        "    extra_in_surr = surr_pred - orig_pred\n",
        "    missing_in_surr = orig_pred - surr_pred\n",
        "\n",
        "    if extra_in_surr or missing_in_surr:\n",
        "        print(f\"\\nDocument {i}:\")\n",
        "        print(f\"  Original text snippet: {results[i]['original'][:100]}...\")\n",
        "        print(f\"  Surrogate text snippet: {results[i]['surrogate'][:100]}...\")\n",
        "\n",
        "        if extra_in_surr:\n",
        "            print(f\"  EXTRA in surrogate: {extra_in_surr}\")\n",
        "        if missing_in_surr:\n",
        "            print(f\"  MISSING in surrogate: {missing_in_surr}\")\n",
        "\n",
        "        print(f\"  Ground truth: {gt}\")\n",
        "        print(f\"  Original predictions: {orig_pred}\")\n",
        "        print(f\"  Surrogate predictions: {surr_pred}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rna4R6hYoNc4",
        "outputId": "d1510162-20ea-458a-eac5-c53c2c7de9b8"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            "DEBUGGING: What's different in surrogate predictions?\n",
            "======================================================================\n",
            "\n",
            "Document 2:\n",
            "  Original text snippet: Robert Davis (SSN: 456-78-9012, email: rdavis@email.com) developed persistent cough and fever. His w...\n",
            "  Surrogate text snippet: Justin Cowan (Crawford-Taylor: 330-05-5107, email: rjenkins@example.org) developed persistent cough ...\n",
            "  EXTRA in surrogate: {'lpneumonia', 'bacteria'}\n",
            "  Ground truth: {'bacterialpneumonia'}\n",
            "  Original predictions: {'bacterialpneumonia', 'fever', 'cough'}\n",
            "  Surrogate predictions: {'bacteria', 'cough', 'bacterialpneumonia', 'fever', 'lpneumonia'}\n",
            "\n",
            "Document 5:\n",
            "  Original text snippet: Sarah Williams (SSN: 789-01-2345) experienced sudden severe headache. Her father had cerebral hemorr...\n",
            "  Surrogate text snippet: Nancy Gilbert (Crawford-Taylor: 493-02-1689) experienced sudden severe headache. Her father had cere...\n",
            "  EXTRA in surrogate: {'headache'}\n",
            "  MISSING in surrogate: {'head'}\n",
            "  Ground truth: {'cerebralhemorrhage'}\n",
            "  Original predictions: {'cerebralhemorrhage', 'head'}\n",
            "  Surrogate predictions: {'cerebralhemorrhage', 'headache'}\n",
            "\n",
            "Document 7:\n",
            "  Original text snippet: Lisa Anderson (email: landerson@email.com) reports chronic fatigue and weakness. Her twin sister Sus...\n",
            "  Surrogate text snippet: Cynthia Arroyo (email: ewilliams@example.org) reports chronic fatigue and weakness. Her twin sister ...\n",
            "  MISSING in surrogate: {'akness'}\n",
            "  Ground truth: {'irondeficiencyanemia', 'anemia'}\n",
            "  Original predictions: {'we', 'anemia', 'chronicfatigue', 'akness', 'irondeficiencyanemia'}\n",
            "  Surrogate predictions: {'irondeficiencyanemia', 'anemia', 'chronicfatigue', 'we'}\n",
            "\n",
            "Document 12:\n",
            "  Original text snippet: Laurent Petit (email: lpetit@example.fr) présente une dysfonction rénale progressive. Son frère Thom...\n",
            "  Surrogate text snippet: Kyle Pierce (email: teresa32@example.org) présente une dysfonction rénale progressive. Son frère Chr...\n",
            "  MISSING in surrogate: {'insuffisancerénalechronique'}\n",
            "  Ground truth: {'insuffisancerénalechronique'}\n",
            "  Original predictions: {'insuffisancerénalechronique', 'dysfonctionrénaleprogressive', 'insuffisancerénalechroni'}\n",
            "  Surrogate predictions: {'dysfonctionrénaleprogressive', 'insuffisancerénalechroni'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qg8iZLQ-fvfg",
        "outputId": "bfb74951-44e6-4d98-919c-2f92b1de86ca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Results saved to /content/drive/MyDrive/NeuroKnow_Results//downstream_utility_results.json\n"
          ]
        }
      ],
      "source": [
        "# Save results to Drive\n",
        "output_dir = \"/content/drive/MyDrive/NeuroKnow_Results/\"\n",
        "!mkdir -p {output_dir}\n",
        "\n",
        "results_summary = {\n",
        "    \"test_documents\": len(results),\n",
        "    \"metrics\": {\n",
        "        \"original\": metrics_original,\n",
        "        \"strict\": metrics_strict,\n",
        "        \"surrogate\": metrics_surrogate\n",
        "    },\n",
        "    \"degradation\": {\n",
        "        \"strict_f1_drop\": strict_degradation,\n",
        "        \"surrogate_f1_drop\": surrogate_degradation,\n",
        "        \"improvement_vs_strict\": strict_degradation - surrogate_degradation\n",
        "    }\n",
        "}\n",
        "\n",
        "with open(f\"{output_dir}/downstream_utility_results.json\", 'w') as f:\n",
        "    json.dump(results_summary, f, indent=2)\n",
        "\n",
        "print(f\"✓ Results saved to {output_dir}/downstream_utility_results.json\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.0"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}