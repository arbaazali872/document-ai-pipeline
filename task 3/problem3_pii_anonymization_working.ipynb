{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Problem 3: Privacy-Preserving Document Processing\n",
        "\n",
        "Building a multilingual PII detection and redaction system for English and French documents.\n",
        "\n",
        "Approach:\n",
        "1. Detection: Regex + spaCy NER\n",
        "2. Redaction: Three strategies - Strict, Typed, Surrogate\n",
        "3. Consistency: Maintain entity mapping for surrogate replacement"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# !pip install spacy faker langdetect\n",
        "# !python -m spacy download fr_core_news_md\n",
        "# !python -m spacy download en_core_web_lg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import re\n",
        "import spacy\n",
        "from faker import Faker\n",
        "from collections import defaultdict\n",
        "import json\n",
        "\n",
        "nlp_fr = spacy.load(\"fr_core_news_md\")\n",
        "nlp_en = spacy.load(\"en_core_web_lg\")\n",
        "\n",
        "faker_fr = Faker('fr_FR')\n",
        "faker_en = Faker('en_US')\n",
        "\n",
        "print(\"✓ All dependencies loaded\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test documents\n",
        "french_medical_doc = \"\"\"Dossier Médical: Patient Marie Dubois (née le 15/03/1978)\n",
        "Sécurité Sociale: 2 78 03 75 116 025 43\n",
        "Adresse: 42 Rue de la République, 59000 Lille\n",
        "Tél: +33 6 12 34 56 78\n",
        "Email: marie.dubois@example.fr\n",
        "Diagnostic: Hypertension (ICD-10: I10)\n",
        "Médecin: Dr. Jean Martin, ID médical: FR789456123\n",
        "\"\"\"\n",
        "\n",
        "french_legal_doc = \"\"\"CONTRAT DE TRAVAIL\n",
        "Entre l'entreprise TechCorp SAS, 15 Avenue des Champs-Élysées, 75008 Paris\n",
        "Et Monsieur Pierre Lefebvre, né le 22/07/1985\n",
        "Numéro de Sécurité Sociale: 1 85 07 75 238 045 12\n",
        "Domicile: 28 Boulevard Voltaire, 75011 Paris\n",
        "Téléphone: +33 1 42 56 78 90\n",
        "Email: p.lefebvre@techcorp.fr\n",
        "Signé à Paris, le 10/01/2024\n",
        "Directeur RH: Mme Sophie Moreau, ID: FR456123789\n",
        "\"\"\"\n",
        "\n",
        "french_financial_doc = \"\"\"RELEVÉ BANCAIRE - Banque de France\n",
        "Titulaire: Mme Isabelle Bernard\n",
        "Date de naissance: 18/11/1990\n",
        "Sécurité Sociale: 2 90 11 92 145 678 23\n",
        "Adresse: 67 Rue de Rivoli, 75001 Paris\n",
        "Téléphone: 06 78 90 12 34\n",
        "Email: isabelle.bernard@gmail.com\n",
        "IBAN: FR76 3000 6000 0112 3456 7890 189\n",
        "Conseiller: M. Laurent Petit, ID: FR234567890\n",
        "Date: 15/12/2023\n",
        "\"\"\"\n",
        "\n",
        "french_edge_cases = \"\"\"DOSSIER CONFIDENTIEL\n",
        "Ancien nom: Marie-Claire Lefèvre-Dubois (née Lefèvre le 31/12/1995)\n",
        "Nouveau nom après mariage: Marie-Claire Martin\n",
        "SSN: 2 95 12 75 456 789 01\n",
        "Téléphone portable: 0612345678\n",
        "Téléphone fixe: +33 (0)1 23 45 67 89\n",
        "Emails: marie.claire@example.fr, mc.martin@work.com\n",
        "Adresse: 123 Rue du Faubourg Saint-Antoine, 75012 Paris\n",
        "Contact d'urgence: Jean Martin (époux), 06-78-90-12-34\n",
        "Médecin: Docteur Sophie Lefebvre, FR890123456\n",
        "\"\"\"\n",
        "\n",
        "consistency_test_doc = \"\"\"SUIVI MÉDICAL\n",
        "Première visite de Marie Dubois le 15/01/2024\n",
        "Marie Dubois (SSN: 2 78 03 75 116 025 43) a consulté.\n",
        "Contact: marie.dubois@example.fr ou +33 6 12 34 56 78\n",
        "\n",
        "Deuxième visite de Marie Dubois le 22/01/2024\n",
        "Marie Dubois a montré des améliorations.\n",
        "\n",
        "Troisième visite de Marie Dubois le 05/02/2024\n",
        "Le dossier de Marie Dubois est à jour.\n",
        "\"\"\"\n",
        "\n",
        "english_medical_doc = \"\"\"Patient Name: John Smith (DOB: 03/15/1978)\n",
        "SSN: 123-45-6789\n",
        "Address: 123 Main Street, New York, NY 10001\n",
        "Phone: (212) 555-1234\n",
        "Email: john.smith@example.com\n",
        "Diagnosis: Hypertension (ICD-10: I10)\n",
        "Physician: Dr. Sarah Johnson, Medical ID: US987654321\n",
        "\"\"\"\n",
        "\n",
        "english_legal_doc = \"\"\"EMPLOYMENT AGREEMENT\n",
        "Between TechCorp Inc., 500 5th Avenue, New York, NY 10110\n",
        "And Ms. Emily Davis, born 07/22/1985\n",
        "Social Security Number: 987-65-4321\n",
        "Address: 789 Broadway, Brooklyn, NY 11211\n",
        "Phone: (646) 555-9876\n",
        "Email: e.davis@techcorp.com\n",
        "Executed in New York, 01/10/2024\n",
        "HR Director: Mr. Michael Brown, ID: US123456789\n",
        "\"\"\"\n",
        "\n",
        "english_financial_doc = \"\"\"BANK STATEMENT - First National Bank\n",
        "Account Holder: Mr. Robert Williams\n",
        "Date of Birth: 11/18/1990\n",
        "SSN: 456-78-9012\n",
        "Address: 456 Park Avenue, Manhattan, NY 10022\n",
        "Phone: (917) 555-4567\n",
        "Email: robert.williams@gmail.com\n",
        "Account #: 1234567890\n",
        "Advisor: Ms. Jennifer Lee, ID: US345678901\n",
        "\"\"\"\n",
        "\n",
        "english_edge_cases = \"\"\"CONFIDENTIAL FILE\n",
        "Former name: Mary-Jane Smith-Johnson (née Smith, DOB: 12/31/1995)\n",
        "Current name: Mary-Jane Williams\n",
        "SSN: 567-89-0123\n",
        "Cell: 6465559876\n",
        "Office: +1 (212) 555-4321\n",
        "Emails: mary.jane@example.com, mj.williams@work.org\n",
        "Address: 123 West 42nd Street, Apt 5B, New York, NY 10036\n",
        "Emergency Contact: John Williams (spouse), 646-555-7890\n",
        "Physician: Doctor Jennifer Smith, US901234567\n",
        "\"\"\"\n",
        "\n",
        "TEST_DOCUMENTS = {\n",
        "    'french': {\n",
        "        'medical': french_medical_doc,\n",
        "        'legal': french_legal_doc,\n",
        "        'financial': french_financial_doc,\n",
        "        'edge_cases': french_edge_cases,\n",
        "        'consistency': consistency_test_doc,\n",
        "    },\n",
        "    'english': {\n",
        "        'medical': english_medical_doc,\n",
        "        'legal': english_legal_doc,\n",
        "        'financial': english_financial_doc,\n",
        "        'edge_cases': english_edge_cases,\n",
        "    }\n",
        "}\n",
        "\n",
        "print(f\"✓ Test documents loaded:\")\n",
        "print(f\"  French: {len(TEST_DOCUMENTS['french'])} documents\")\n",
        "print(f\"  English: {len(TEST_DOCUMENTS['english'])} documents\")\n",
        "print(f\"  Total: {sum(len(docs) for docs in TEST_DOCUMENTS.values())} documents\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Language detection\n",
        "def detect_language(text):\n",
        "    french_indicators = ['le', 'la', 'de', 'et', 'à', 'du', 'Sécurité Sociale', 'Adresse', 'Tél']\n",
        "    english_indicators = ['the', 'and', 'of', 'to', 'SSN', 'Address', 'Phone']\n",
        "    \n",
        "    french_score = sum(1 for word in french_indicators if word in text)\n",
        "    english_score = sum(1 for word in english_indicators if word in text)\n",
        "    \n",
        "    return 'fr' if french_score > english_score else 'en'\n",
        "\n",
        "# Quick test\n",
        "print(\"French doc:\", detect_language(french_medical_doc))\n",
        "print(\"English doc:\", detect_language(english_medical_doc))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Regex patterns for PII\n",
        "FRENCH_PHONE_PATTERNS = [\n",
        "    r'\\+33\\s\\d\\s\\d{2}\\s\\d{2}\\s\\d{2}\\s\\d{2}',\n",
        "    r'\\+33\\d\\s?\\d{2}\\s?\\d{2}\\s?\\d{2}\\s?\\d{2}',\n",
        "    r'0[1-9]\\s\\d{2}\\s\\d{2}\\s\\d{2}\\s\\d{2}',\n",
        "    r'0[1-9][\\.-]\\d{2}[\\.-]\\d{2}[\\.-]\\d{2}[\\.-]\\d{2}',\n",
        "    r'0[1-9]\\d{8}',\n",
        "]\n",
        "\n",
        "ENGLISH_PHONE_PATTERNS = [\n",
        "    r'\\+?1?\\s?\\(?\\d{3}\\)?[\\s\\.-]?\\d{3}[\\s\\.-]?\\d{4}',\n",
        "    r'\\d{10}',\n",
        "]\n",
        "\n",
        "FRENCH_SSN_PATTERNS = [\n",
        "    r'[12]\\s?\\d{2}\\s?\\d{2}\\s?\\d{2}\\s?\\d{3}\\s?\\d{3}\\s?\\d{2}',\n",
        "]\n",
        "\n",
        "US_SSN_PATTERNS = [\n",
        "    r'\\d{3}[-\\s]?\\d{2}[-\\s]?\\d{4}',\n",
        "]\n",
        "\n",
        "EMAIL_PATTERN = r'\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\\b'\n",
        "DATE_PATTERNS = [r'\\b\\d{2}[/-]\\d{2}[/-]\\d{4}\\b']\n",
        "FRENCH_POSTAL_PATTERN = r'\\b\\d{5}\\b'\n",
        "US_ZIPCODE_PATTERN = r'\\b\\d{5}(?:-\\d{4})?\\b'\n",
        "MEDICAL_ID_PATTERN = r'\\b[A-Z]{2}\\d{9}\\b'\n",
        "IBAN_PATTERN = r'\\b[A-Z]{2}\\d{2}[\\s]?(?:\\d{4}[\\s]?){4,7}\\d{1,4}\\b'\n",
        "\n",
        "def detect_pii_regex(text, language=None):\n",
        "    if language is None:\n",
        "        language = detect_language(text)\n",
        "    \n",
        "    entities = []\n",
        "    \n",
        "    # Email\n",
        "    for match in re.finditer(EMAIL_PATTERN, text):\n",
        "        entities.append({\n",
        "            'type': 'EMAIL',\n",
        "            'text': match.group(),\n",
        "            'start': match.start(),\n",
        "            'end': match.end(),\n",
        "            'method': 'regex'\n",
        "        })\n",
        "    \n",
        "    # Phone numbers\n",
        "    if language == 'fr':\n",
        "        for pattern in FRENCH_PHONE_PATTERNS:\n",
        "            for match in re.finditer(pattern, text):\n",
        "                entities.append({\n",
        "                    'type': 'FR_PHONE',\n",
        "                    'text': match.group(),\n",
        "                    'start': match.start(),\n",
        "                    'end': match.end(),\n",
        "                    'method': 'regex'\n",
        "                })\n",
        "    else:\n",
        "        for pattern in ENGLISH_PHONE_PATTERNS:\n",
        "            for match in re.finditer(pattern, text):\n",
        "                matched_text = match.group()\n",
        "                if len(matched_text) == 10 and matched_text.isdigit():\n",
        "                    start = max(0, match.start() - 20)\n",
        "                    end = min(len(text), match.end() + 20)\n",
        "                    context = text[start:end].lower()\n",
        "                    if not any(word in context for word in ['phone', 'tel', 'call', 'contact', 'cell', 'mobile']):\n",
        "                        continue\n",
        "                \n",
        "                entities.append({\n",
        "                    'type': 'US_PHONE',\n",
        "                    'text': matched_text,\n",
        "                    'start': match.start(),\n",
        "                    'end': match.end(),\n",
        "                    'method': 'regex'\n",
        "                })\n",
        "    \n",
        "    # SSN\n",
        "    if language == 'fr':\n",
        "        for pattern in FRENCH_SSN_PATTERNS:\n",
        "            for match in re.finditer(pattern, text):\n",
        "                entities.append({\n",
        "                    'type': 'FR_SSN',\n",
        "                    'text': match.group(),\n",
        "                    'start': match.start(),\n",
        "                    'end': match.end(),\n",
        "                    'method': 'regex'\n",
        "                })\n",
        "    else:\n",
        "        for pattern in US_SSN_PATTERNS:\n",
        "            for match in re.finditer(pattern, text):\n",
        "                entities.append({\n",
        "                    'type': 'US_SSN',\n",
        "                    'text': match.group(),\n",
        "                    'start': match.start(),\n",
        "                    'end': match.end(),\n",
        "                    'method': 'regex'\n",
        "                })\n",
        "    \n",
        "    # Dates\n",
        "    for match in re.finditer(DATE_PATTERNS[0], text):\n",
        "        entities.append({\n",
        "            'type': 'DATE',\n",
        "            'text': match.group(),\n",
        "            'start': match.start(),\n",
        "            'end': match.end(),\n",
        "            'method': 'regex'\n",
        "        })\n",
        "    \n",
        "    # Postal codes\n",
        "    if language == 'fr':\n",
        "        for match in re.finditer(FRENCH_POSTAL_PATTERN, text):\n",
        "            entities.append({\n",
        "                'type': 'FR_POSTAL',\n",
        "                'text': match.group(),\n",
        "                'start': match.start(),\n",
        "                'end': match.end(),\n",
        "                'method': 'regex'\n",
        "            })\n",
        "    else:\n",
        "        for match in re.finditer(US_ZIPCODE_PATTERN, text):\n",
        "            entities.append({\n",
        "                'type': 'US_ZIPCODE',\n",
        "                'text': match.group(),\n",
        "                'start': match.start(),\n",
        "                'end': match.end(),\n",
        "                'method': 'regex'\n",
        "            })\n",
        "    \n",
        "    # Medical IDs\n",
        "    for match in re.finditer(MEDICAL_ID_PATTERN, text):\n",
        "        entities.append({\n",
        "            'type': 'MEDICAL_ID',\n",
        "            'text': match.group(),\n",
        "            'start': match.start(),\n",
        "            'end': match.end(),\n",
        "            'method': 'regex'\n",
        "        })\n",
        "    \n",
        "    # IBAN for French docs\n",
        "    if language == 'fr':\n",
        "        for match in re.finditer(IBAN_PATTERN, text):\n",
        "            entities.append({\n",
        "                'type': 'IBAN',\n",
        "                'text': match.group(),\n",
        "                'start': match.start(),\n",
        "                'end': match.end(),\n",
        "                'method': 'regex'\n",
        "            })\n",
        "    \n",
        "    return entities\n",
        "\n",
        "# Test\n",
        "print(\"Testing Regex Detection:\\n\")\n",
        "print(\"=\"*70)\n",
        "print(\"FRENCH MEDICAL DOCUMENT\")\n",
        "print(\"=\"*70)\n",
        "detected_lang = detect_language(french_medical_doc)\n",
        "print(f\"Detected Language: {detected_lang}\\n\")\n",
        "fr_regex_entities = detect_pii_regex(french_medical_doc)\n",
        "for entity in fr_regex_entities:\n",
        "    print(f\"  {entity['type']:15s}: {entity['text']}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"ENGLISH MEDICAL DOCUMENT\")\n",
        "print(\"=\"*70)\n",
        "detected_lang = detect_language(english_medical_doc)\n",
        "print(f\"Detected Language: {detected_lang}\\n\")\n",
        "en_regex_entities = detect_pii_regex(english_medical_doc)\n",
        "for entity in en_regex_entities:\n",
        "    print(f\"  {entity['type']:15s}: {entity['text']}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# NER detection with spaCy\n",
        "def detect_pii_ner(text):\n",
        "    language = detect_language(text)\n",
        "    nlp = nlp_fr if language == 'fr' else nlp_en\n",
        "    doc = nlp(text)\n",
        "    \n",
        "    # print(\"got the doc like:\",doc,\"\\n end of doc\\nentities detected are:\",doc.ents)\n",
        "    entities = []\n",
        "    \n",
        "    pii_mapping = {\n",
        "        'PER': 'PERSON',\n",
        "        'PERSON': 'PERSON',\n",
        "        'LOC': 'LOCATION',\n",
        "        'GPE': 'LOCATION',\n",
        "        'ORG': 'ORGANIZATION',\n",
        "        'DATE': 'DATE',\n",
        "    }\n",
        "    \n",
        "    for ent in doc.ents:\n",
        "        if ent.label_ in pii_mapping:\n",
        "            entities.append({\n",
        "                'type': pii_mapping[ent.label_],\n",
        "                'text': ent.text,\n",
        "                'start': ent.start_char,\n",
        "                'end': ent.end_char,\n",
        "                'method': 'ner',\n",
        "                'language': language\n",
        "            })\n",
        "    \n",
        "    return entities\n",
        "\n",
        "print(\"Testing NER Detection:\\n\")\n",
        "print(\"=\"*70)\n",
        "print(\"FRENCH MEDICAL DOCUMENT\")\n",
        "print(\"=\"*70)\n",
        "fr_ner_entities = detect_pii_ner(french_medical_doc)\n",
        "print(f\"Detected Language: {fr_ner_entities[0]['language'] if fr_ner_entities else 'N/A'}\\n\")\n",
        "for entity in fr_ner_entities:\n",
        "    print(f\"  {entity['type']:15s}: {entity['text']}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"ENGLISH MEDICAL DOCUMENT\")\n",
        "print(\"=\"*70)\n",
        "en_ner_entities = detect_pii_ner(english_medical_doc)\n",
        "print(f\"Detected Language: {en_ner_entities[0]['language'] if en_ner_entities else 'N/A'}\\n\")\n",
        "for entity in en_ner_entities:\n",
        "    print(f\"  {entity['type']:15s}: {entity['text']}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Hybrid detection - combine regex and NER\n",
        "def detect_pii_hybrid(text):\n",
        "    regex_entities = detect_pii_regex(text)\n",
        "    ner_entities = detect_pii_ner(text)\n",
        "    \n",
        "    all_entities = regex_entities + ner_entities\n",
        "    \n",
        "    # Remove duplicates based on overlapping positions\n",
        "    unique_entities = []\n",
        "    for entity in all_entities:\n",
        "        overlap = False\n",
        "        for existing in unique_entities:\n",
        "            if (entity['start'] < existing['end'] and entity['end'] > existing['start']):\n",
        "                if entity['method'] == 'regex':\n",
        "                    overlap = True\n",
        "                    break\n",
        "        if not overlap:\n",
        "            unique_entities.append(entity)\n",
        "    \n",
        "    return sorted(unique_entities, key=lambda x: x['start'])\n",
        "\n",
        "print(\"FRENCH MEDICAL DOCUMENT - Hybrid Detection:\")\n",
        "fr_hybrid_entities = detect_pii_hybrid(french_medical_doc)\n",
        "for entity in fr_hybrid_entities:\n",
        "    print(f\"  {entity['type']:15s}: {entity['text']:30s} [{entity['method']}]\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
        "\n",
        "print(\"ENGLISH MEDICAL DOCUMENT - Hybrid Detection:\")\n",
        "en_hybrid_entities = detect_pii_hybrid(english_medical_doc)\n",
        "for entity in en_hybrid_entities:\n",
        "    print(f\"  {entity['type']:15s}: {entity['text']:30s} [{entity['method']}]\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Redaction Strategy 1: Strict\n",
        "def redact_strict(text, entities):\n",
        "    sorted_entities = sorted(entities, key=lambda x: x['start'], reverse=True)\n",
        "    redacted_text = text\n",
        "    for entity in sorted_entities:\n",
        "        redacted_text = redacted_text[:entity['start']] + '[REDACTED]' + redacted_text[entity['end']:]\n",
        "    return redacted_text\n",
        "\n",
        "print(\"Strict Redaction - French:\")\n",
        "print(redact_strict(french_medical_doc, fr_hybrid_entities))\n",
        "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
        "print(\"Strict Redaction - English:\")\n",
        "print(redact_strict(english_medical_doc, en_hybrid_entities))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Redaction Strategy 2: Typed\n",
        "def redact_typed(text, entities):\n",
        "    type_mapping = {\n",
        "        'PERSON': 'NAME',\n",
        "        'FR_SSN': 'SSN',\n",
        "        'US_SSN': 'SSN',\n",
        "        'FR_PHONE': 'PHONE',\n",
        "        'US_PHONE': 'PHONE',\n",
        "        'EMAIL': 'EMAIL',\n",
        "        'LOCATION': 'ADDRESS',\n",
        "        'DATE': 'DATE',\n",
        "        'MEDICAL_ID': 'MEDICAL_ID',\n",
        "        'FR_POSTAL': 'ZIPCODE',\n",
        "        'US_ZIPCODE': 'ZIPCODE',\n",
        "    }\n",
        "    \n",
        "    sorted_entities = sorted(entities, key=lambda x: x['start'], reverse=True)\n",
        "    redacted_text = text\n",
        "    for entity in sorted_entities:\n",
        "        entity_type = type_mapping.get(entity['type'], entity['type'])\n",
        "        redacted_text = (\n",
        "            redacted_text[:entity['start']] +\n",
        "            f'[{entity_type}]' +\n",
        "            redacted_text[entity['end']:]\n",
        "        )\n",
        "    \n",
        "    return redacted_text\n",
        "\n",
        "print(\"Typed Redaction - French:\")\n",
        "print(redact_typed(french_medical_doc, fr_hybrid_entities))\n",
        "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
        "print(\"Typed Redaction - English:\")\n",
        "print(redact_typed(english_medical_doc, en_hybrid_entities))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Redaction Strategy 3: Surrogate with Faker\n",
        "# Maintains consistency - same entity always maps to same fake value\n",
        "\n",
        "def generate_surrogate(entity_type, original_text, language, mapping):\n",
        "    # Check existing mapping\n",
        "    if original_text in mapping[entity_type]:\n",
        "        return mapping[entity_type][original_text]\n",
        "    \n",
        "    faker = faker_fr if language == 'fr' else faker_en\n",
        "    seed = hash(original_text) % (2**32)\n",
        "    Faker.seed(seed)\n",
        "    \n",
        "    if entity_type == 'PERSON':\n",
        "        surrogate = faker.name()\n",
        "    elif entity_type in ['FR_SSN', 'US_SSN']:\n",
        "        if language == 'fr':\n",
        "            surrogate = f\"{faker.random_int(1, 2)} {faker.random_int(10, 99)} {faker.random_int(10, 99)} {faker.random_int(10, 99)} {faker.random_int(100, 999)} {faker.random_int(100, 999)} {faker.random_int(10, 99)}\"\n",
        "        else:\n",
        "            surrogate = faker.ssn()\n",
        "    elif entity_type in ['FR_PHONE', 'US_PHONE']:\n",
        "        surrogate = faker.phone_number()\n",
        "    elif entity_type == 'EMAIL':\n",
        "        surrogate = faker.email()\n",
        "    elif entity_type == 'LOCATION':\n",
        "        surrogate = faker.address().replace('\\n', ', ')\n",
        "    elif entity_type == 'DATE':\n",
        "        surrogate = faker.date(pattern='%d/%m/%Y')\n",
        "    elif entity_type == 'MEDICAL_ID':\n",
        "        prefix = 'FR' if language == 'fr' else 'US'\n",
        "        surrogate = f\"{prefix}{faker.random_number(digits=9)}\"\n",
        "    elif entity_type in ['FR_POSTAL', 'US_ZIPCODE']:\n",
        "        surrogate = faker.postcode()\n",
        "    elif entity_type == 'ORGANIZATION':\n",
        "        surrogate = faker.company()\n",
        "    elif entity_type == 'IBAN':\n",
        "        surrogate = faker.iban()\n",
        "    else:\n",
        "        surrogate = '[UNKNOWN]'\n",
        "    \n",
        "    mapping[entity_type][original_text] = surrogate\n",
        "    return surrogate\n",
        "\n",
        "def redact_surrogate(text, entities):\n",
        "    language = detect_language(text)\n",
        "    mapping = defaultdict(dict)\n",
        "    \n",
        "    sorted_entities = sorted(entities, key=lambda x: x['start'], reverse=True)\n",
        "    redacted_text = text\n",
        "    \n",
        "    for entity in sorted_entities:\n",
        "        surrogate = generate_surrogate(entity['type'], entity['text'], language, mapping)\n",
        "        redacted_text = (\n",
        "            redacted_text[:entity['start']] +\n",
        "            surrogate +\n",
        "            redacted_text[entity['end']:]\n",
        "        )\n",
        "    \n",
        "    return redacted_text, mapping\n",
        "\n",
        "print(\"Surrogate Redaction - French:\")\n",
        "fr_surrogate, fr_mapping = redact_surrogate(french_medical_doc, fr_hybrid_entities)\n",
        "print(fr_surrogate)\n",
        "print(\"\\nMapping Stats:\")\n",
        "stats = {k: len(v) for k, v in fr_mapping.items()}\n",
        "print(json.dumps(stats, indent=2))\n",
        "\n",
        "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
        "\n",
        "print(\"Surrogate Redaction - English:\")\n",
        "en_surrogate, en_mapping = redact_surrogate(english_medical_doc, en_hybrid_entities)\n",
        "print(en_surrogate)\n",
        "print(\"\\nMapping Stats:\")\n",
        "stats = {k: len(v) for k, v in en_mapping.items()}\n",
        "print(json.dumps(stats, indent=2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test consistency - same entity should map to same fake value\n",
        "test_consistency_doc = \"\"\"Patient Marie Dubois visited on 15/03/2023.\n",
        "Marie Dubois has email marie.dubois@example.fr.\n",
        "Contact Marie Dubois at +33 6 12 34 56 78.\n",
        "Marie Dubois's SSN: 2 78 03 75 116 025 43\n",
        "\"\"\"\n",
        "\n",
        "print(\"Original Document with Repeated Entities:\")\n",
        "print(test_consistency_doc)\n",
        "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
        "\n",
        "consistency_entities = detect_pii_hybrid(test_consistency_doc)\n",
        "print(\"Detected Entities:\")\n",
        "for entity in consistency_entities:\n",
        "    print(f\"  {entity['type']:15s}: {entity['text']}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
        "\n",
        "redacted_consistency, consistency_mapping = redact_surrogate(test_consistency_doc, consistency_entities)\n",
        "print(\"Surrogate Redacted (with Consistency):\")\n",
        "print(redacted_consistency)\n",
        "\n",
        "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
        "\n",
        "print(\"Consistency Mapping:\")\n",
        "for entity_type, mappings in consistency_mapping.items():\n",
        "    print(f\"\\n{entity_type}:\")\n",
        "    for original, fake in mappings.items():\n",
        "        print(f\"  {original} → {fake}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Evaluation metrics\n",
        "def calculate_metrics_by_type_text_based(predicted_entities, ground_truth_entities):\n",
        "    metrics_by_type = defaultdict(lambda: {'tp': 0, 'fp': 0, 'fn': 0})\n",
        "    \n",
        "    predicted_set = {(e['type'], e['text'].strip()) for e in predicted_entities}\n",
        "    ground_truth_set = {(e['type'], e['text'].strip()) for e in ground_truth_entities}\n",
        "    \n",
        "    # True positives\n",
        "    for entity_type, text in predicted_set & ground_truth_set:\n",
        "        metrics_by_type[entity_type]['tp'] += 1\n",
        "    \n",
        "    # False positives\n",
        "    for entity_type, text in predicted_set - ground_truth_set:\n",
        "        metrics_by_type[entity_type]['fp'] += 1\n",
        "    \n",
        "    # False negatives\n",
        "    for entity_type, text in ground_truth_set - predicted_set:\n",
        "        metrics_by_type[entity_type]['fn'] += 1\n",
        "    \n",
        "    return dict(metrics_by_type)\n",
        "\n",
        "# Test cases with ground truth\n",
        "EVALUATION_TEST_SET = [\n",
        "    {\n",
        "        'id': 'test_fr_001',\n",
        "        'text': \"Rapport: Marie Dubois, né le 15/03/1985, SSN: 2 78 03 75 116 025 43, Tel: 06 12 34 56 78, Email: marie.dubois@gmail.com\",\n",
        "        'ground_truth': [\n",
        "            {'type': 'PERSON', 'text': 'Marie Dubois'},\n",
        "            {'type': 'DATE', 'text': '15/03/1985'},\n",
        "            {'type': 'FR_SSN', 'text': '2 78 03 75 116 025 43'},\n",
        "            {'type': 'FR_PHONE', 'text': '06 12 34 56 78'},\n",
        "            {'type': 'EMAIL', 'text': 'marie.dubois@gmail.com'},\n",
        "        ]\n",
        "    },\n",
        "    {\n",
        "        'id': 'test_en_001',\n",
        "        'text': \"Patient: John Smith, DOB: 03/15/1990, SSN: 123-45-6789, Phone: (212) 555-1234, Email: john.smith@email.com\",\n",
        "        'ground_truth': [\n",
        "            {'type': 'PERSON', 'text': 'John Smith'},\n",
        "            {'type': 'DATE', 'text': '03/15/1990'},\n",
        "            {'type': 'US_SSN', 'text': '123-45-6789'},\n",
        "            {'type': 'US_PHONE', 'text': '(212) 555-1234'},\n",
        "            {'type': 'EMAIL', 'text': 'john.smith@email.com'},\n",
        "        ]\n",
        "    }\n",
        "]\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"EVALUATION ON TEST SET (Text-based matching)\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "all_metrics = defaultdict(lambda: {'tp': 0, 'fp': 0, 'fn': 0})\n",
        "\n",
        "for test_case in EVALUATION_TEST_SET:\n",
        "    print(f\"\\n{test_case['id']}:\")\n",
        "    print(f\"  Text: {test_case['text'][:80]}...\")\n",
        "    \n",
        "    predicted = detect_pii_hybrid(test_case['text'])\n",
        "    \n",
        "    detected_str = ', '.join([f\"{e['type']}:{e['text']}\" for e in predicted])\n",
        "    expected_str = ', '.join([f\"{e['type']}:{e['text']}\" for e in test_case['ground_truth']])\n",
        "    \n",
        "    print(f\"  Detected: {detected_str}\")\n",
        "    print(f\"  Expected: {expected_str}\")\n",
        "    \n",
        "    doc_metrics = calculate_metrics_by_type_text_based(predicted, test_case['ground_truth'])\n",
        "    \n",
        "    for entity_type, metrics in doc_metrics.items():\n",
        "        all_metrics[entity_type]['tp'] += metrics['tp']\n",
        "        all_metrics[entity_type]['fp'] += metrics['fp']\n",
        "        all_metrics[entity_type]['fn'] += metrics['fn']\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"RESULTS BY ENTITY TYPE\")\n",
        "print(\"=\"*70)\n",
        "print(f\"\\n{'Entity Type':<15} {'Precision':<12} {'Recall':<12} {'F1 Score':<12} {'TP':<6} {'FP':<6} {'FN':<6}\")\n",
        "print(\"-\"*70)\n",
        "\n",
        "overall_tp = overall_fp = overall_fn = 0\n",
        "\n",
        "for entity_type in sorted(all_metrics.keys()):\n",
        "    counts = all_metrics[entity_type]\n",
        "    tp, fp, fn = counts['tp'], counts['fp'], counts['fn']\n",
        "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
        "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "    f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
        "    \n",
        "    print(f\"{entity_type:<15} {precision:<12.3f} {recall:<12.3f} {f1:<12.3f} {tp:<6} {fp:<6} {fn:<6}\")\n",
        "    \n",
        "    overall_tp += tp\n",
        "    overall_fp += fp\n",
        "    overall_fn += fn\n",
        "\n",
        "print(\"-\"*70)\n",
        "overall_precision = overall_tp / (overall_tp + overall_fp) if (overall_tp + overall_fp) > 0 else 0\n",
        "overall_recall = overall_tp / (overall_tp + overall_fn) if (overall_tp + overall_fn) > 0 else 0\n",
        "overall_f1 = 2 * (overall_precision * overall_recall) / (overall_precision + overall_recall) if (overall_precision + overall_recall) > 0 else 0\n",
        "\n",
        "print(f\"{'OVERALL':<15} {overall_precision:<12.3f} {overall_recall:<12.3f} {overall_f1:<12.3f} {overall_tp:<6} {overall_fp:<6} {overall_fn:<6}\")\n",
        "print(\"=\"*70)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Complete pipeline function\n",
        "def anonymize_document(text, strategy='surrogate'):\n",
        "    language = detect_language(text)\n",
        "    entities = detect_pii_hybrid(text)\n",
        "    \n",
        "    if strategy == 'strict':\n",
        "        redacted_text = redact_strict(text, entities)\n",
        "        mapping = None\n",
        "    elif strategy == 'typed':\n",
        "        redacted_text = redact_typed(text, entities)\n",
        "        mapping = None\n",
        "    elif strategy == 'surrogate':\n",
        "        redacted_text, mapping = redact_surrogate(text, entities)\n",
        "    else:\n",
        "        raise ValueError(f\"Unknown strategy: {strategy}\")\n",
        "    \n",
        "    return {\n",
        "        'original_text': text,\n",
        "        'redacted_text': redacted_text,\n",
        "        'entities_detected': entities,\n",
        "        'num_entities': len(entities),\n",
        "        'language': language,\n",
        "        'strategy': strategy,\n",
        "        'mapping': mapping\n",
        "    }\n",
        "\n",
        "# Test all documents with all strategies\n",
        "print(\"=\"*70)\n",
        "print(\"TESTING ALL DOCUMENTS WITH ALL STRATEGIES\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "for lang, documents in TEST_DOCUMENTS.items():\n",
        "    print(f\"\\n{'='*70}\")\n",
        "    print(f\"LANGUAGE: {lang.upper()}\")\n",
        "    print(f\"{'='*70}\")\n",
        "    \n",
        "    for doc_type, doc_text in documents.items():\n",
        "        print(f\"\\n{'-'*70}\")\n",
        "        print(f\"Document Type: {doc_type}\")\n",
        "        print(f\"{'-'*70}\")\n",
        "        \n",
        "        for strategy in ['strict', 'typed', 'surrogate']:\n",
        "            print(f\"\\n\\n{'-'*70}\")\n",
        "            print(f\"Strategy: {strategy.upper()}\")\n",
        "            print(f\"{'-'*70}\")\n",
        "            \n",
        "            result = anonymize_document(doc_text, strategy)\n",
        "            \n",
        "            # print(f\"got the doc like: {doc_text} \\n end of doc\")\n",
        "            entities = result['entities_detected']\n",
        "            # print(f\"entities detected are: {tuple(e['text'] for e in entities)}\")\n",
        "            \n",
        "            print(f\"Detected language: {result['language']}\")\n",
        "            print(f\"Entities detected: {result['num_entities']}\")\n",
        "            \n",
        "            entity_counts = defaultdict(int)\n",
        "            for entity in entities:\n",
        "                entity_counts[entity['type']] += 1\n",
        "            print(f\"Entity breakdown: {dict(entity_counts)}\")\n",
        "            \n",
        "            print(f\"\\nRedacted text:\")\n",
        "            print(result['redacted_text'])\n",
        "            \n",
        "            if strategy == 'surrogate' and result['mapping']:\n",
        "                print(f\"\\nMappings created: {sum(len(v) for v in result['mapping'].values())} unique values\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"TESTING COMPLETE\")\n",
        "print(\"=\"*70)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary\n",
        "\n",
        "### What We've Built:\n",
        "1. Detection: Hybrid approach (Regex + spaCy NER)\n",
        "2. Three Redaction Strategies: Strict, Typed, Surrogate\n",
        "3. Consistency: Same entity → same surrogate\n",
        "4. Multilingual: English + French support\n",
        "\n",
        "### Key Findings:\n",
        "- Regex: Fast, precise for structured PII (SSN, email, phone)\n",
        "- NER: Better for unstructured PII (names, locations)\n",
        "- Hybrid: Combines strengths of both approaches\n",
        "- Surrogate: Best preserves utility for downstream tasks\n",
        "- Consistency: Critical for maintaining semantic relationships"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
